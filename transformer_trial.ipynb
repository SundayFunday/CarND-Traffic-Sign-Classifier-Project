{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from six.moves import cPickle as pickle\n",
    "import math\n",
    "from time import time\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train.p', 'rb') as train_f:\n",
    "    train = pickle.load(train_f)\n",
    "with open('test.p', 'rb') as test_f:\n",
    "    test = pickle.load(test_f)\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return cv2.normalize(image,None,-1.0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize images\n",
    "X_train = np.array([normalize(image) for image in X_train], dtype=np.float32)\n",
    "X_test = np.array([normalize(image) for image in X_test], dtype=np.float32)\n",
    "\n",
    "#flatten images\n",
    "X_train_flat = np.array([image.flatten() for image in X_train])\n",
    "X_test_flat = np.array([image.flatten() for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot-encode-labels\n",
    "train_labels = dense_to_one_hot(y_train, n_classes=43)\n",
    "test_labels = dense_to_one_hot(y_test, n_classes=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_size = 32\n",
    "n_channels = 3\n",
    "n_features = im_size*im_size*n_channels\n",
    "n_labels = 43\n",
    "\n",
    "\n",
    "n_loc_layer_2 = 200\n",
    "n_loc_layer_3 = 20\n",
    "n_tranforms = 6\n",
    "trans_out_size = (im_size, im_size)\n",
    "\n",
    "conv_layer_5_filter_size = 5\n",
    "conv_layer_5_num_filters = 50\n",
    "\n",
    "conv_layer_6_filter_size = 5\n",
    "conv_layer_6_num_filters = 100\n",
    "\n",
    "n_fc_layer_7 = 1024\n",
    "n_fc_layer_8 = 200\n",
    "\n",
    "features = tf.placeholder(dtype=tf.float32, shape=[None, n_features])\n",
    "labels = tf.placeholder(dtype= tf.float32, shape=[None, n_labels])\n",
    "\n",
    "features_tensor = tf.reshape(features, shape=[-1,im_size,im_size,n_channels])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformer(U, theta, out_size, name='SpatialTransformer', **kwargs):\n",
    "    \"\"\"Spatial Transformer Layer\n",
    "    Implements a spatial transformer layer as described in [1]_.\n",
    "    Based on [2]_ and edited by David Dao for Tensorflow.\n",
    "    Parameters\n",
    "    ----------\n",
    "    U : float\n",
    "        The output of a convolutional net should have the\n",
    "        shape [num_batch, height, width, num_channels].\n",
    "    theta: float\n",
    "        The output of the\n",
    "        localisation network should be [num_batch, 6].\n",
    "    out_size: tuple of two ints\n",
    "        The size of the output of the network (height, width)\n",
    "    References\n",
    "    ----------\n",
    "    .. [1]  Spatial Transformer Networks\n",
    "            Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu\n",
    "            Submitted on 5 Jun 2015\n",
    "    .. [2]  https://github.com/skaae/transformer_network/blob/master/transformerlayer.py\n",
    "    Notes\n",
    "    -----\n",
    "    To initialize the network to the identity transform init\n",
    "    ``theta`` to :\n",
    "        identity = np.array([[1., 0., 0.],\n",
    "                             [0., 1., 0.]])\n",
    "        identity = identity.flatten()\n",
    "        theta = tf.Variable(initial_value=identity)\n",
    "    \"\"\"\n",
    "\n",
    "    def _repeat(x, n_repeats):\n",
    "        with tf.variable_scope('_repeat'):\n",
    "            rep = tf.transpose(\n",
    "                tf.expand_dims(tf.ones(shape=tf.pack([n_repeats, ])), 1), [1, 0])\n",
    "            rep = tf.cast(rep, 'int32')\n",
    "            x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n",
    "            return tf.reshape(x, [-1])\n",
    "\n",
    "    def _interpolate(im, x, y, out_size):\n",
    "        with tf.variable_scope('_interpolate'):\n",
    "            # constants\n",
    "            num_batch = tf.shape(im)[0]\n",
    "            height = tf.shape(im)[1]\n",
    "            width = tf.shape(im)[2]\n",
    "            channels = tf.shape(im)[3]\n",
    "\n",
    "            x = tf.cast(x, 'float32')\n",
    "            y = tf.cast(y, 'float32')\n",
    "            height_f = tf.cast(height, 'float32')\n",
    "            width_f = tf.cast(width, 'float32')\n",
    "            out_height = out_size[0]\n",
    "            out_width = out_size[1]\n",
    "            zero = tf.zeros([], dtype='int32')\n",
    "            max_y = tf.cast(tf.shape(im)[1] - 1, 'int32')\n",
    "            max_x = tf.cast(tf.shape(im)[2] - 1, 'int32')\n",
    "\n",
    "            # scale indices from [-1, 1] to [0, width/height]\n",
    "            x = (x + 1.0)*(width_f) / 2.0\n",
    "            y = (y + 1.0)*(height_f) / 2.0\n",
    "\n",
    "            # do sampling\n",
    "            x0 = tf.cast(tf.floor(x), 'int32')\n",
    "            x1 = x0 + 1\n",
    "            y0 = tf.cast(tf.floor(y), 'int32')\n",
    "            y1 = y0 + 1\n",
    "\n",
    "            x0 = tf.clip_by_value(x0, zero, max_x)\n",
    "            x1 = tf.clip_by_value(x1, zero, max_x)\n",
    "            y0 = tf.clip_by_value(y0, zero, max_y)\n",
    "            y1 = tf.clip_by_value(y1, zero, max_y)\n",
    "            dim2 = width\n",
    "            dim1 = width*height\n",
    "            base = _repeat(tf.range(num_batch)*dim1, out_height*out_width)\n",
    "            base_y0 = base + y0*dim2\n",
    "            base_y1 = base + y1*dim2\n",
    "            idx_a = base_y0 + x0\n",
    "            idx_b = base_y1 + x0\n",
    "            idx_c = base_y0 + x1\n",
    "            idx_d = base_y1 + x1\n",
    "\n",
    "            # use indices to lookup pixels in the flat image and restore\n",
    "            # channels dim\n",
    "            im_flat = tf.reshape(im, tf.pack([-1, channels]))\n",
    "            im_flat = tf.cast(im_flat, 'float32')\n",
    "            Ia = tf.gather(im_flat, idx_a)\n",
    "            Ib = tf.gather(im_flat, idx_b)\n",
    "            Ic = tf.gather(im_flat, idx_c)\n",
    "            Id = tf.gather(im_flat, idx_d)\n",
    "\n",
    "            # and finally calculate interpolated values\n",
    "            x0_f = tf.cast(x0, 'float32')\n",
    "            x1_f = tf.cast(x1, 'float32')\n",
    "            y0_f = tf.cast(y0, 'float32')\n",
    "            y1_f = tf.cast(y1, 'float32')\n",
    "            wa = tf.expand_dims(((x1_f-x) * (y1_f-y)), 1)\n",
    "            wb = tf.expand_dims(((x1_f-x) * (y-y0_f)), 1)\n",
    "            wc = tf.expand_dims(((x-x0_f) * (y1_f-y)), 1)\n",
    "            wd = tf.expand_dims(((x-x0_f) * (y-y0_f)), 1)\n",
    "            output = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "            return output\n",
    "\n",
    "    def _meshgrid(height, width):\n",
    "        with tf.variable_scope('_meshgrid'):\n",
    "            # This should be equivalent to:\n",
    "            #  x_t, y_t = np.meshgrid(np.linspace(-1, 1, width),\n",
    "            #                         np.linspace(-1, 1, height))\n",
    "            #  ones = np.ones(np.prod(x_t.shape))\n",
    "            #  grid = np.vstack([x_t.flatten(), y_t.flatten(), ones])\n",
    "            #\n",
    "            # x_t = tf.matmul(tf.ones(shape=tf.pack([height, 1])),\n",
    "            #                 tf.transpose(tf.expand_dims(tf.linspace(-1.0, 1.0, width), 1), [1, 0]))\n",
    "            # y_t = tf.matmul(tf.expand_dims(tf.linspace(-1.0, 1.0, height), 1),\n",
    "            #                 tf.ones(shape=tf.pack([1, width])))\n",
    "\n",
    "            x_t, y_t = tf.meshgrid(tf.linspace(-1.0, 1.0, width),\n",
    "                                   tf.linspace(-1.0, 1.0, height))\n",
    "            x_t_flat = tf.reshape(x_t, (1, -1))\n",
    "            y_t_flat = tf.reshape(y_t, (1, -1))\n",
    "            \n",
    "            ones = tf.ones_like(x_t_flat)\n",
    "            grid = tf.concat(0, [x_t_flat, y_t_flat, ones])\n",
    "            return grid\n",
    "\n",
    "    def _transform(theta, input_dim, out_size):\n",
    "        with tf.variable_scope('_transform'):\n",
    "            num_batch = tf.shape(input_dim)[0]\n",
    "            height = tf.shape(input_dim)[1]\n",
    "            width = tf.shape(input_dim)[2]\n",
    "            num_channels = tf.shape(input_dim)[3]\n",
    "            theta = tf.reshape(theta, (-1, 2, 3))\n",
    "            theta = tf.cast(theta, 'float32')\n",
    "\n",
    "            # grid of (x_t, y_t, 1), eq (1) in ref [1]\n",
    "            height_f = tf.cast(height, 'float32')\n",
    "            width_f = tf.cast(width, 'float32')\n",
    "            out_height = out_size[0]\n",
    "            out_width = out_size[1]\n",
    "            grid = _meshgrid(out_height, out_width)\n",
    "            grid = tf.expand_dims(grid, 0)\n",
    "            grid = tf.reshape(grid, [-1])\n",
    "            grid = tf.tile(grid, tf.pack([num_batch]))\n",
    "            grid = tf.reshape(grid, tf.pack([num_batch, 3, -1]))\n",
    "\n",
    "            # Transform A x (x_t, y_t, 1)^T -> (x_s, y_s)\n",
    "            T_g = tf.batch_matmul(theta, grid)\n",
    "            x_s = tf.slice(T_g, [0, 0, 0], [-1, 1, -1])\n",
    "            y_s = tf.slice(T_g, [0, 1, 0], [-1, 1, -1])\n",
    "            x_s_flat = tf.reshape(x_s, [-1])\n",
    "            y_s_flat = tf.reshape(y_s, [-1])\n",
    "\n",
    "            input_transformed = _interpolate(\n",
    "                input_dim, x_s_flat, y_s_flat,\n",
    "                out_size)\n",
    "\n",
    "            output = tf.reshape(\n",
    "                input_transformed, tf.pack([num_batch, out_height, out_width, num_channels]))\n",
    "            return output\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        output = _transform(theta, U, out_size)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_layer_1 = fc_layer(input = features,\n",
    "                       num_inputs = n_features ,\n",
    "                       num_outputs = n_loc_layer_2,\n",
    "                       non_lin='tanh'\n",
    "                       )\n",
    "loc_layer_1 = tf.nn.dropout(loc_layer_1, keep_prob=keep_prob)\n",
    "\n",
    "loc_layer_2 = fc_layer(input = loc_layer_1,\n",
    "                       num_inputs = n_loc_layer_2 ,\n",
    "                       num_outputs = n_loc_layer_3,\n",
    "                       non_lin='tanh'\n",
    "                       )\n",
    "loc_layer_2 = tf.nn.dropout(loc_layer_2, keep_prob=keep_prob)\n",
    "\n",
    "loc_layer_3 = fc_layer(input = loc_layer_2,\n",
    "                       num_inputs = n_loc_layer_3 ,\n",
    "                       num_outputs = n_tranforms,\n",
    "                       non_lin='tanh'\n",
    "                       )\n",
    "\n",
    "\n",
    "trans_layer_4 = transformer(features_tensor, loc_layer_3, trans_out_size)\n",
    "\n",
    "conv_layer_5 = conv_layer(input = trans_layer_4,\n",
    "                          num_input_channels = n_channels,\n",
    "                          filter_size = conv_layer_5_filter_size,\n",
    "                          num_filters = conv_layer_5_num_filters,\n",
    "                          use_pooling=True,\n",
    "                          non_lin='relu')\n",
    "\n",
    "conv_layer_6 = conv_layer(input = conv_layer_5,\n",
    "                          num_input_channels = conv_layer_5_num_filters,\n",
    "                          filter_size = conv_layer_6_filter_size,\n",
    "                          num_filters = conv_layer_6_num_filters,\n",
    "                          use_pooling=True,\n",
    "                          non_lin='relu')\n",
    "\n",
    "conv_layer_6_flat, layer_6_flat_feature_count = flatten_layer(conv_layer_6)\n",
    "\n",
    "fc_layer_7 = fc_layer(input = conv_layer_6_flat,\n",
    "                      num_inputs = layer_6_flat_feature_count,\n",
    "                      num_outputs = n_fc_layer_7,\n",
    "                      non_lin='relu'\n",
    "                      )\n",
    "\n",
    "fc_layer_7 = tf.nn.dropout(fc_layer_7, keep_prob=keep_prob)\n",
    "\n",
    "fc_layer_8 = fc_layer(input = fc_layer_7,\n",
    "                      num_inputs = n_fc_layer_7,\n",
    "                      num_outputs = n_fc_layer_8,\n",
    "                      non_lin='relu'\n",
    "                      )\n",
    "\n",
    "fc_layer_8 = tf.nn.dropout(fc_layer_8, keep_prob=keep_prob)\n",
    "\n",
    "fc_layer_9 = fc_layer(input = fc_layer_8,\n",
    "                      num_inputs = n_fc_layer_8,\n",
    "                      num_outputs = n_labels,\n",
    "                      non_lin=None\n",
    "                      )\n",
    "\n",
    "predictions = tf.nn.softmax(fc_layer_9)\n",
    "cross_entorpy = tf.nn.softmax_cross_entropy_with_logits(logits=fc_layer_9, labels=labels)\n",
    "loss = tf.reduce_mean(cross_entorpy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, acutals):\n",
    "    prediction_labels = np.argmax(predictions, axis=1)\n",
    "    actual_labels = np.argmax(acutals, axis=1)\n",
    "    return np.mean(np.equal(prediction_labels, actual_labels).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class(in_features, in_labels, sess):\n",
    "    batch_size = 250\n",
    "    batch_count = int(math.ceil(len(in_features)/batch_size)) \n",
    "    class_predictions = np.zeros_like(in_labels)\n",
    "    for i in range(batch_count):\n",
    "        batch_start = i*batch_size\n",
    "        batch_end = batch_start+batch_size\n",
    "        batch_features = in_features[batch_start : batch_end]\n",
    "        batch_labels = in_labels[batch_start : batch_end]\n",
    "        feed_dict = {features: batch_features,\n",
    "                     labels: batch_labels,\n",
    "                     keep_prob: 1.0\n",
    "                     }\n",
    "        class_predictions[batch_start:batch_end] = sess.run(predictions, feed_dict=feed_dict)\n",
    "    return class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 0.211\n",
      "Time taken = 4.942\n",
      "Time taken = 4.972\n",
      "Time taken = 5.059\n",
      "Time taken = 5.036\n",
      "Time taken = 4.972\n",
      "Time taken = 4.933\n",
      "Time taken = 4.961\n",
      "Time taken = 5.014\n",
      "Time taken = 4.983\n",
      "Time taken = 4.997\n",
      "Time taken = 4.996\n",
      "Time taken = 4.967\n",
      "Time taken = 4.983\n",
      "Time taken = 4.999\n",
      "Time taken = 5.016\n",
      "Time taken = 5.021\n",
      "Time taken = 5.003\n",
      "Time taken = 5.005\n",
      "Time taken = 5.033\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_count = int(math.ceil(len(X_train)/batch_size))\n",
    "    start_time = time()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_features, batch_labels in batch_generator(X_train,\n",
    "                                                            train_labels,\n",
    "                                                            batch_count,\n",
    "                                                            batch_size):\n",
    "            batch_features_flat = np.array([image.flatten() for image in batch_features])\n",
    "            feed_dict = {features: batch_features_flat,\n",
    "                         labels: batch_labels,\n",
    "                         keep_prob: 0.8\n",
    "                         }\n",
    "            _, l = sess.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        \n",
    "        if epoch%25 == 0:\n",
    "            print(\"Time taken = {}\".format(round((time() - start_time)/60.0 , 3)))\n",
    "            start_time = time()\n",
    "    \n",
    "    \n",
    "    train_predictions = predict_class(in_features=X_train_flat,\n",
    "                                      in_labels=train_labels,\n",
    "                                      sess=sess)\n",
    "    test_predictions = predict_class(in_features=X_test_flat,\n",
    "                                     in_labels=test_labels,\n",
    "                                     sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9860000014305115\n",
      "Test Accuracy: 0.9449999928474426\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = get_accuracy(train_predictions, train_labels)\n",
    "test_accuracy = get_accuracy(test_predictions, test_labels)\n",
    "print('Training Accuracy: {}'.format(round(training_accuracy, 3)))\n",
    "print('Test Accuracy: {}'.format(round(test_accuracy, 3)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
